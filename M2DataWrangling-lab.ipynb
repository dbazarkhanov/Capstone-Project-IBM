{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "prev_pub_hash": "90ac80ca41fde58b95f02cc0cfc0a0f2ed3115615ffe1bdfdfc10fd5ffeef9a4"
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"400\" alt=\"Skills Network Logo\"  />\n    </a>\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# **Data Wrangling Lab**\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Estimated time needed: **45 to 60** minutes\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this assignment you will be performing data wrangling.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Objectives\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this lab you will perform the following:\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "-   Identify duplicate values in the dataset.\n\n-   Remove duplicate values from the dataset.\n\n-   Identify missing values in the dataset.\n\n-   Impute the missing values in the dataset.\n\n-   Normalize data in the dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<hr>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Hands on Lab\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Import pandas module.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-1-7dd3504c366f>:1: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "Load the dataset into a dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Read Data</h2>\n<p>\nWe utilize the <code>pandas.read_csv()</code> function for reading CSV files. However, in this version of the lab, which operates on JupyterLite, the dataset needs to be downloaded to the interface using the provided code below.\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The functions below will download the dataset into your browser:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "To obtain the dataset, utilize the download() function as defined above:  \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "await download(file_path, \"m1_survey_data.csv\")\nfile_name=\"m1_survey_data.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": "Utilize the Pandas method read_csv() to load the data into a dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv(file_name)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "> Note: This version of the lab is working on JupyterLite, which requires the dataset to be downloaded to the interface.While working on the downloaded version of this notebook on their local machines(Jupyter Anaconda), the learners can simply **skip the steps above,** and simply use the URL directly in the `pandas.read_csv()` function. You can uncomment and run the statements in the cell below.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Finding duplicates\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this section you will identify duplicate values in the dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": " Find how many duplicate rows exist in the dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.duplicated().sum()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "154"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "source": "## Removing duplicates\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Remove the duplicate rows from the dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.drop_duplicates(inplace=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 20
    },
    {
      "cell_type": "markdown",
      "source": "Verify if duplicates were actually dropped.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.duplicated().sum()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": "## Finding Missing values\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Find the missing values for all columns.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.isna().sum()\ndf.info()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nIndex: 11398 entries, 0 to 11551\nData columns (total 85 columns):\n #   Column                  Non-Null Count  Dtype  \n---  ------                  --------------  -----  \n 0   Respondent              11398 non-null  int64  \n 1   MainBranch              11398 non-null  object \n 2   Hobbyist                11398 non-null  object \n 3   OpenSourcer             11398 non-null  object \n 4   OpenSource              11317 non-null  object \n 5   Employment              11398 non-null  object \n 6   Country                 11398 non-null  object \n 7   Student                 11347 non-null  object \n 8   EdLevel                 11286 non-null  object \n 9   UndergradMajor          10661 non-null  object \n 10  EduOther                11234 non-null  object \n 11  OrgSize                 11302 non-null  object \n 12  DevType                 11333 non-null  object \n 13  YearsCode               11389 non-null  object \n 14  Age1stCode              11385 non-null  object \n 15  YearsCodePro            11382 non-null  object \n 16  CareerSat               11398 non-null  object \n 17  JobSat                  11397 non-null  object \n 18  MgrIdiot                10905 non-null  object \n 19  MgrMoney                10901 non-null  object \n 20  MgrWant                 10905 non-null  object \n 21  JobSeek                 11398 non-null  object \n 22  LastHireDate            11398 non-null  object \n 23  LastInt                 10985 non-null  object \n 24  FizzBuzz                11361 non-null  object \n 25  JobFactors              11395 non-null  object \n 26  ResumeUpdate            11359 non-null  object \n 27  CurrencySymbol          11398 non-null  object \n 28  CurrencyDesc            11398 non-null  object \n 29  CompTotal               10589 non-null  float64\n 30  CompFreq                11192 non-null  object \n 31  ConvertedComp           10582 non-null  float64\n 32  WorkWeekHrs             11276 non-null  float64\n 33  WorkPlan                11277 non-null  object \n 34  WorkChallenge           11234 non-null  object \n 35  WorkRemote              11390 non-null  object \n 36  WorkLoc                 11366 non-null  object \n 37  ImpSyn                  11393 non-null  object \n 38  CodeRev                 11397 non-null  object \n 39  CodeRevHrs              8972 non-null   float64\n 40  UnitTests               11369 non-null  object \n 41  PurchaseHow             11202 non-null  object \n 42  PurchaseWhat            11360 non-null  object \n 43  LanguageWorkedWith      11387 non-null  object \n 44  LanguageDesireNextYear  11264 non-null  object \n 45  DatabaseWorkedWith      10945 non-null  object \n 46  DatabaseDesireNextYear  10356 non-null  object \n 47  PlatformWorkedWith      10987 non-null  object \n 48  PlatformDesireNextYear  10854 non-null  object \n 49  WebFrameWorkedWith      10005 non-null  object \n 50  WebFrameDesireNextYear  9781 non-null   object \n 51  MiscTechWorkedWith      9216 non-null   object \n 52  MiscTechDesireNextYear  9943 non-null   object \n 53  DevEnviron              11369 non-null  object \n 54  OpSys                   11364 non-null  object \n 55  Containers              11316 non-null  object \n 56  BlockchainOrg           9076 non-null   object \n 57  BlockchainIs            8788 non-null   object \n 58  BetterLife              11300 non-null  object \n 59  ITperson                11363 non-null  object \n 60  OffOn                   11360 non-null  object \n 61  SocialMedia             11105 non-null  object \n 62  Extraversion            11378 non-null  object \n 63  ScreenName              10891 non-null  object \n 64  SOVisit1st              11073 non-null  object \n 65  SOVisitFreq             11393 non-null  object \n 66  SOVisitTo               11397 non-null  object \n 67  SOFindAnswer            11395 non-null  object \n 68  SOTimeSaved             11348 non-null  object \n 69  SOHowMuchTime           9481 non-null   object \n 70  SOAccount               11397 non-null  object \n 71  SOPartFreq              10270 non-null  object \n 72  SOJobs                  11392 non-null  object \n 73  EntTeams                11393 non-null  object \n 74  SOComm                  11398 non-null  object \n 75  WelcomeChange           11313 non-null  object \n 76  SONewContent            9433 non-null   object \n 77  Age                     11111 non-null  float64\n 78  Gender                  11325 non-null  object \n 79  Trans                   11275 non-null  object \n 80  Sexuality               10856 non-null  object \n 81  Ethnicity               10723 non-null  object \n 82  Dependents              11258 non-null  object \n 83  SurveyLength            11379 non-null  object \n 84  SurveyEase              11384 non-null  object \ndtypes: float64(5), int64(1), object(79)\nmemory usage: 4.0+ MB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 32
    },
    {
      "cell_type": "markdown",
      "source": "Find out how many rows are missing in the column 'WorkLoc'\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.WorkLoc.isna().sum()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 41,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ],
      "execution_count": 41
    },
    {
      "cell_type": "markdown",
      "source": "## Imputing missing values\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Find the  value counts for the column WorkLoc.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.WorkLoc.value_counts()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 38,
          "output_type": "execute_result",
          "data": {
            "text/plain": "WorkLoc\nOffice                                            6806\nHome                                              3589\nOther place, such as a coworking space or cafe     971\nName: count, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 38
    },
    {
      "cell_type": "markdown",
      "source": "Identify the value that is most frequent (majority) in the WorkLoc column.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#make a note of the majority value here, for future reference\n#Most frequent (majority) in the WorkLoc column is \"Office\"",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Impute (replace) all the empty rows in the column WorkLoc with the value that you have identified as majority.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.WorkLoc.fillna('Office')",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 40,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0                                                  Home\n1                                                Office\n2                                                  Home\n3                                                  Home\n4        Other place, such as a coworking space or cafe\n                              ...                      \n11547                                              Home\n11548                                              Home\n11549                                            Office\n11550                                              Home\n11551                                            Office\nName: WorkLoc, Length: 11398, dtype: object"
          },
          "metadata": {}
        }
      ],
      "execution_count": 40
    },
    {
      "cell_type": "markdown",
      "source": "After imputation there should ideally not be any empty rows in the WorkLoc column.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Verify if imputing was successful.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.WorkLoc.isna().sum()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 42,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ],
      "execution_count": 42
    },
    {
      "cell_type": "markdown",
      "source": "## Normalizing data\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "There are two columns in the dataset that talk about compensation.\n\nOne is \"CompFreq\". This column shows how often a developer is paid (Yearly, Monthly, Weekly).\n\nThe other is \"CompTotal\". This column talks about how much the developer is paid per Year, Month, or Week depending upon his/her \"CompFreq\". \n\nThis makes it difficult to compare the total compensation of the developers.\n\nIn this section you will create a new column called 'NormalizedAnnualCompensation' which contains the 'Annual Compensation' irrespective of the 'CompFreq'.\n\nOnce this column is ready, it makes comparison of salaries easy.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<hr>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "List out the various categories in the column 'CompFreq'\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.CompFreq.unique()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 48,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array(['Yearly', 'Monthly', 'Weekly', nan], dtype=object)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 48
    },
    {
      "cell_type": "markdown",
      "source": "Create a new column named 'NormalizedAnnualCompensation'. Use the hint given below if needed.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Double click to see the **Hint**.\n\n<!--\n\nUse the below logic to arrive at the values for the column NormalizedAnnualCompensation.\n\nIf the CompFreq is Yearly then use the exising value in CompTotal\nIf the CompFreq is Monthly then multiply the value in CompTotal with 12 (months in an year)\nIf the CompFreq is Weekly then multiply the value in CompTotal with 52 (weeks in an year)\n\n-->\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def normalize_compensation(row):\n    if row['CompFreq'] == 'Yearly':\n        return row['CompTotal']\n    elif row['CompFreq'] == 'Monthly':\n        return row['CompTotal'] * 12\n    elif row['CompFreq'] == 'Weekly':\n        return row['CompTotal'] * 52\n    else:\n        return None\n\ndf['NormalizedAnnualCompensation'] = df.apply(normalize_compensation, axis=1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 49
    },
    {
      "cell_type": "code",
      "source": "df.NormalizedAnnualCompensation.median()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 51,
          "output_type": "execute_result",
          "data": {
            "text/plain": "100000.0"
          },
          "metadata": {}
        }
      ],
      "execution_count": 51
    },
    {
      "cell_type": "markdown",
      "source": "## Authors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Ramesh Sannareddy\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Other Contributors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Rav Ahuja\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": " Copyright Â© 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<!--## Change Log\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<!--| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n| ----------------- | ------- | ----------------- | ---------------------------------- |\n| 2020-10-17        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |--!>\n",
      "metadata": {}
    }
  ]
}